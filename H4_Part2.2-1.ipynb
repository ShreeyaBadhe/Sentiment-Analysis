{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f62d8d5-da3a-477c-89c9-1ca0b5e9d5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 2.2 question 1 \n",
    "#perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "650caf90-59a1-4202-9e4a-57583868920d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, update 31.1%, dev 37.4%\n",
      "epoch 2, update 29.5%, dev 35.4%\n",
      "epoch 3, update 29.8%, dev 33.2%\n",
      "epoch 4, update 29.1%, dev 40.0%\n",
      "epoch 5, update 29.7%, dev 35.2%\n",
      "epoch 6, update 29.4%, dev 40.4%\n",
      "epoch 7, update 29.4%, dev 38.4%\n",
      "epoch 8, update 29.4%, dev 42.5%\n",
      "epoch 9, update 29.1%, dev 39.0%\n",
      "epoch 10, update 29.1%, dev 39.2%\n",
      "best dev err 33.2%, time: 6.7 secs\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics import accuracy_score\n",
    "from __future__ import division\n",
    "\n",
    "# Load word vectors\n",
    "wv = KeyedVectors.load('embs_train.kv')\n",
    "\n",
    "# Function to compute the sentence embedding\n",
    "def sentence_embedding(sentence):\n",
    "    tokens = sentence.split()\n",
    "    embeddings = []\n",
    "    for token in tokens:\n",
    "        if token in wv:  # Check if the token has a word vector\n",
    "            embeddings.append(wv[token])\n",
    "    if len(embeddings) > 0:\n",
    "        # Return the average embedding\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        # Return a zero vector if no embeddings were found\n",
    "        return np.zeros(wv.vector_size)\n",
    "\n",
    "# Function to process the data row by row\n",
    "def read_from(dataframe):\n",
    "    for i, row in dataframe.iterrows():\n",
    "        label = 1 if row['target'] == '+' else -1  # Convert label to numeric\n",
    "        yield (label, row['Review_Embedding'])\n",
    "\n",
    "# Test the model\n",
    "def test(dev_data, model):\n",
    "    tot, err = 0, 0\n",
    "    for label, emb in read_from(dev_data):\n",
    "        err += label * (np.dot(model, emb)) <= 0\n",
    "    return err / len(dev_data)\n",
    "\n",
    "# Train the model using a perceptron-like algorithm\n",
    "def train(train_data, dev_data, epochs=10):\n",
    "    t = time.time()\n",
    "    best_err = 1.0\n",
    "    model = np.zeros(train_data['Review_Embedding'].iloc[0].shape)  # Initialize model as zero vector\n",
    "    \n",
    "    for it in range(1, epochs + 1):\n",
    "        updates = 0\n",
    "        for label, emb in read_from(train_data):\n",
    "            if label * (np.dot(model, emb)) <= 0:  # Perceptron update rule\n",
    "                updates += 1\n",
    "                model += label * emb\n",
    "        dev_err = test(dev_data, model)\n",
    "        best_err = min(best_err, dev_err)\n",
    "        print(\"epoch %d, update %.1f%%, dev %.1f%%\" % (it, updates / len(train_data) * 100, dev_err * 100))\n",
    "    \n",
    "    print(\"best dev err %.1f%%, time: %.1f secs\" % (best_err * 100, time.time() - t))\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    # Load training and development data\n",
    "    train_data = pd.read_csv('train.csv')  \n",
    "    dev_data = pd.read_csv('dev.csv')    \n",
    "\n",
    "    # Compute sentence embeddings and add them as a new column\n",
    "    train_data['Review_Embedding'] = train_data['sentence'].apply(sentence_embedding)\n",
    "    dev_data['Review_Embedding'] = dev_data['sentence'].apply(sentence_embedding)\n",
    "\n",
    "    # Train the model\n",
    "    train(train_data, dev_data, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750830eb-63a6-4569-8ecc-5b12f91afa08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
